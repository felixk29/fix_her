{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lists of papers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day ones:  \n",
    "\n",
    " - [HER](https://arxiv.org/pdf/1707.01495.pdf) the GOAT obviously \n",
    " \n",
    " - [Go Explore](https://arxiv.org/pdf/1901.10995.pdf) breakthrough algorithm for exploration of rl, 1. part is finding path via teleport exploration 2. is robusting path, considered cheating as it just loads states and sets to deterministic,\n",
    "\n",
    " - [Max Paper](https://arxiv.org/pdf/2306.05727.pdf) introduces the problem of generalization across topologys also has experiments I will yoink probably\n",
    "\n",
    " - [Generalized Hindsight for Reinforcement Learning](https://proceedings.neurips.cc/paper_files/paper/2020/file/57e5cb96e22546001f1d6520ff11d9ba-Paper.pdf) generalized version of HER with adaption to learn generalized goals better\n",
    "\n",
    " - [A Survey of Zero-shot Generalisation in Deep Reinforcement Learning](https://dl.acm.org/doi/10.1613/jair.1.14174) 2023, survey, very insightfull, cmdp etc.. definitions fresh for the yoinking, also tables interesting (table 1.-3.)\n",
    "  \n",
    " - [On the Importance of Exploration for Generalization in Reinforcement Learning](https://arxiv.org/pdf/2306.05483.pdf) rl specific investigation into exploration/generalization, very similar to mine, hopefully different enough (it is cause it doesnt do anything new or crazy, just investigates, crazy good paper for me), but definetly shows that exploration helps generalization in RL which is key thing to acknowledge, no focus on reachability, figure 3, implies that state has to be seen, which kinda isnt generalization,\n",
    "\n",
    " - [Efficient Self-Supervised Data Collection for Offline Robot Learning](https://arxiv.org/abs/2105.04607) very similar idea to mine but very much focussed on robotics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side pieces:  \n",
    "\n",
    " - [Learning Montezumaâ€™s Revenge from a Single Demonstration](https://arxiv.org/pdf/1812.03381.pdf) utilized by go explore to robust learned path, as go explore just figures out 1 path so absolutely overfitted\n",
    "\n",
    " - [Zero-Shot Generalization MC](https://proceedings.mlr.press/v70/oh17a/oh17a.pdf) agent learns \"do x regarding a\", \"do y regarding b\" has to zero shot generalize to \"do x regarding b\" \n",
    "\n",
    " - [From one game to many](https://openreview.net/pdf?id=sSt9fROSZRO) trains on x variants of an atari game, tries to generalize/finetune for x+y games, more of an investigative paper than new methodology, uses IMPALA (actor-critic)\n",
    " \n",
    " - [Multi-task Batch Reinforcement Learning with Metric Learning](https://proceedings.neurips.cc/paper/2020/hash/4496bf24afe7fab6f046bf4923da8de6-Abstract.html) learn unseen tasks from the same distribution as the seen task, but no task identifier, task identifier has to be implicitly learned, \n",
    "\n",
    " - [A Survey of Multi-Task Deep Reinforcement Learning](https://www.mdpi.com/2079-9292/9/9/1363) a survey\n",
    "\n",
    " - [Deep Decentralized Multi-task Multi-Agent Reinforcement Learning under Partial Observability](https://proceedings.mlr.press/v70/omidshafiei17a.html) just put it here becuase its \"Suffering the paper\", will prob not be included\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
